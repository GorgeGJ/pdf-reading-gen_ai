{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de7c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685f1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c2e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ollama is running.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Check if Ollama is running\n",
    "import requests\n",
    "\n",
    "def is_ollama_running():\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434\")\n",
    "        if response.status_code == 200:\n",
    "            return True\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "if is_ollama_running():\n",
    "    print(\"‚úÖ Ollama is running.\")\n",
    "else:\n",
    "    print(\"‚ùå Ollama is NOT running. Please start it with: `ollama run llama3`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc467ad",
   "metadata": {},
   "source": [
    "# üìì Ask My PDFs ‚Äì Demo Notebook\n",
    "This notebook shows how to:\n",
    "- Embed multiple PDFs\n",
    "- Run retrieval-augmented generation queries\n",
    "- Use local LLMs via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2984282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: There is no paper mentioned in the provided context. The text appears to be a summary of educational background and professional experience.\n"
     ]
    }
   ],
   "source": [
    "from rag_utils import load_and_split_pdfs, embed_documents, query_ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 1: Load and embed documents\n",
    "docs = load_and_split_pdfs(\"pdfs\")\n",
    "# vectordb = embed_documents(docs, persist_dir=\"chroma_db\")\n",
    "vectordb = embed_documents(docs)\n",
    "\n",
    "# Step 2: Ask a question\n",
    "retriever = vectordb.as_retriever()\n",
    "query = \"What is the main topic of the paper?\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# Step 3: Generate answer using Ollama\n",
    "response = query_ollama(context, query)\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee081608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the provided context, here is a summary of Jie Gao's professional background:\n",
      "\n",
      "* Currently working as a Senior Data Scientist at Walmart in Hoboken, New Jersey (since September 2021)\n",
      "* Has over 5 years of experience in customer and marketing analysis, data integrity, modeling, and visualization\n",
      "* Awarded \"Driven of Result\" under in 2023 Winter, rated exemplary during the 1st year in Walmart\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "query = \"Can you summarize their professional background?\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# Generate answer using Ollama\n",
    "response = query_ollama(context, query)\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1bfdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Master's degree. The candidate has a Master in Econometrics and Quantitative Economics from New York University, completed from September 2018 to May 2020.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "query = \"What is this candidate's education level\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# Generate answer using Ollama\n",
    "response = query_ollama(context, query)\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc31856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes, according to the context, Jie Gao has MMM (Marketing Mix Modeling) experience. The summary mentions:\n",
      "\n",
      "* Developed an in-house Bayesian Hierarchy MMM solution to measure the incremental media contribution on driving High Value Action customers.\n",
      "* Utilized MMM to optimize marketing budgets, achieving an average 3% increase in marketing ROI.\n",
      "\n",
      "This indicates that Jie Gao has hands-on experience with MMM and its applications in optimizing marketing budgets.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "query = \"Does this candidate has MMM experience\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "context = \"\\n\".join([doc.page_content for doc in relevant_docs[:3]])\n",
    "\n",
    "# Generate answer using Ollama\n",
    "response = query_ollama(context, query)\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663120c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
